{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Allie Surina\n",
    "## Capstone Project: Predicting Disabled List Placements \n",
    "\n",
    "### Project Goal: \n",
    "To game log data for MLB games from 2000 - 2016, along with whether a player was placed on the Disabled List after a particular game (i.e. he was injured during his previous game), and predict whether a a Disabled List placement will happen to a starting player for a game.\n",
    "\n",
    "### Data:\n",
    "* `games_dls.csv` Merged data from `games.csv` and `injury.csv` that is the basis of the model.\n",
    "\n",
    "### Methods:\n",
    "* I plan to use machine learning classification model to predict whether a disabled list placement will happen after a particular game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the game and disabled list merged data from games_dls.csv\n",
    "file = './datasets/games_features_for_model.csv'\n",
    "df = pd.read_csv(file,index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Sklearn Packages for Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score,\\\n",
    "                        precision_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('date', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Injury columns is multi-class, so I need to create a binary column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    36399\n",
       "1     4893\n",
       "Name: injury, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.injury = df.injury.map(lambda x: 1 if x>0 else 0)\n",
    "df.injury.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in df.columns if 'injury' not in col]\n",
    "X = df.loc[:,cols]\n",
    "y = df.loc[:,'injury']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.index = pd.to_datetime(X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 41292 entries, 2000-03-29 to 2016-10-02\n",
      "Data columns (total 180 columns):\n",
      "num_game                int64\n",
      "v_team_game_num         int64\n",
      "h_team_game_num         int64\n",
      "v_team_score            int64\n",
      "h_team_score            int64\n",
      "game_length_outs        int64\n",
      "attendance              float64\n",
      "time_game_min           int64\n",
      "v_at_bats               int64\n",
      "v_hits                  int64\n",
      "v_doubles               int64\n",
      "v_triples               int64\n",
      "v_homeruns              int64\n",
      "v_RBI                   int64\n",
      "v_sac_hits              int64\n",
      "v_sac_files             int64\n",
      "v_hit_pitch             int64\n",
      "v_walks                 int64\n",
      "v_int_walks             int64\n",
      "v_strikeouts            int64\n",
      "v_stol_base             int64\n",
      "v_caught_steal          int64\n",
      "v_grnd_dbl_plays        int64\n",
      "v_awd_fst_catch_intf    int64\n",
      "v_left_on_base          int64\n",
      "v_pitchers              int64\n",
      "v_ind_earn_runs         int64\n",
      "v_team_earn_runs        int64\n",
      "v_wild_pitch            int64\n",
      "v_balks                 int64\n",
      "v_putouts               int64\n",
      "v_assists               int64\n",
      "v_errors                int64\n",
      "v_pass_balls            int64\n",
      "v_dbl_plays             int64\n",
      "v_trp_plays             int64\n",
      "h_at_bats               int64\n",
      "h_hits                  int64\n",
      "h_doubles               int64\n",
      "h_triples               int64\n",
      "h_homeruns              int64\n",
      "h_RBI                   int64\n",
      "h_sac_hits              int64\n",
      "h_sac_files             int64\n",
      "h_hit_pitch             int64\n",
      "h_walks                 int64\n",
      "h_int_walks             int64\n",
      "h_strikeouts            int64\n",
      "h_stol_base             int64\n",
      "h_caught_steal          int64\n",
      "h_grnd_dbl_plays        int64\n",
      "h_awd_fst_catch_intf    int64\n",
      "h_left_on_base          int64\n",
      "h_pitchers              int64\n",
      "h_ind_earn_runs         int64\n",
      "h_team_earn_runs        int64\n",
      "h_wild_pitch            int64\n",
      "h_balks                 int64\n",
      "h_putouts               int64\n",
      "h_assists               int64\n",
      "h_errors                int64\n",
      "h_pass_balls            int64\n",
      "h_dbl_plays             int64\n",
      "h_trp_plays             int64\n",
      "intra_league            int64\n",
      "day_Mon                 int64\n",
      "day_Sat                 int64\n",
      "day_Sun                 int64\n",
      "day_Thu                 int64\n",
      "day_Tue                 int64\n",
      "day_Wed                 int64\n",
      "v_team_ARI              int64\n",
      "v_team_ATL              int64\n",
      "v_team_BAL              int64\n",
      "v_team_BOS              int64\n",
      "v_team_CHA              int64\n",
      "v_team_CHN              int64\n",
      "v_team_CIN              int64\n",
      "v_team_CLE              int64\n",
      "v_team_COL              int64\n",
      "v_team_DET              int64\n",
      "v_team_FLO              int64\n",
      "v_team_HOU              int64\n",
      "v_team_KCA              int64\n",
      "v_team_LAN              int64\n",
      "v_team_MIA              int64\n",
      "v_team_MIL              int64\n",
      "v_team_MIN              int64\n",
      "v_team_MON              int64\n",
      "v_team_NYA              int64\n",
      "v_team_NYN              int64\n",
      "v_team_OAK              int64\n",
      "v_team_PHI              int64\n",
      "v_team_PIT              int64\n",
      "v_team_SDN              int64\n",
      "v_team_SEA              int64\n",
      "v_team_SFN              int64\n",
      "v_team_SLN              int64\n",
      "v_team_TBA              int64\n",
      "v_team_TEX              int64\n",
      "v_team_TOR              int64\n",
      "v_team_WAS              int64\n",
      "h_team_ARI              int64\n",
      "h_team_ATL              int64\n",
      "h_team_BAL              int64\n",
      "h_team_BOS              int64\n",
      "h_team_CHA              int64\n",
      "h_team_CHN              int64\n",
      "h_team_CIN              int64\n",
      "h_team_CLE              int64\n",
      "h_team_COL              int64\n",
      "h_team_DET              int64\n",
      "h_team_FLO              int64\n",
      "h_team_HOU              int64\n",
      "h_team_KCA              int64\n",
      "h_team_LAN              int64\n",
      "h_team_MIA              int64\n",
      "h_team_MIL              int64\n",
      "h_team_MIN              int64\n",
      "h_team_MON              int64\n",
      "h_team_NYA              int64\n",
      "h_team_NYN              int64\n",
      "h_team_OAK              int64\n",
      "h_team_PHI              int64\n",
      "h_team_PIT              int64\n",
      "h_team_SDN              int64\n",
      "h_team_SEA              int64\n",
      "h_team_SFN              int64\n",
      "h_team_SLN              int64\n",
      "h_team_TBA              int64\n",
      "h_team_TEX              int64\n",
      "h_team_TOR              int64\n",
      "h_team_WAS              int64\n",
      "day_night_N             int64\n",
      "park_id_ARL02           int64\n",
      "park_id_ATL02           int64\n",
      "park_id_BAL12           int64\n",
      "park_id_BOS07           int64\n",
      "park_id_CHI11           int64\n",
      "park_id_CHI12           int64\n",
      "park_id_CIN08           int64\n",
      "park_id_CIN09           int64\n",
      "park_id_CLE08           int64\n",
      "park_id_DEN02           int64\n",
      "park_id_DET05           int64\n",
      "park_id_FTB01           int64\n",
      "park_id_HOU03           int64\n",
      "park_id_KAN06           int64\n",
      "park_id_LBV01           int64\n",
      "park_id_LOS03           int64\n",
      "park_id_MIA01           int64\n",
      "park_id_MIA02           int64\n",
      "park_id_MIL05           int64\n",
      "park_id_MIL06           int64\n",
      "park_id_MIN03           int64\n",
      "park_id_MIN04           int64\n",
      "park_id_MON02           int64\n",
      "park_id_NYC16           int64\n",
      "park_id_NYC17           int64\n",
      "park_id_NYC20           int64\n",
      "park_id_NYC21           int64\n",
      "park_id_OAK01           int64\n",
      "park_id_PHI12           int64\n",
      "park_id_PHI13           int64\n",
      "park_id_PHO01           int64\n",
      "park_id_PIT07           int64\n",
      "park_id_PIT08           int64\n",
      "park_id_SAN01           int64\n",
      "park_id_SAN02           int64\n",
      "park_id_SEA03           int64\n",
      "park_id_SFO03           int64\n",
      "park_id_SJU01           int64\n",
      "park_id_STL09           int64\n",
      "park_id_STL10           int64\n",
      "park_id_STP01           int64\n",
      "park_id_SYD01           int64\n",
      "park_id_TOK01           int64\n",
      "park_id_TOR02           int64\n",
      "park_id_WAS10           int64\n",
      "park_id_WAS11           int64\n",
      "dtypes: float64(1), int64(179)\n",
      "memory usage: 57.0 MB\n"
     ]
    }
   ],
   "source": [
    "X.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    36399\n",
       "1     4893\n",
       "Name: injury, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish the Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8815024702121477"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the Baseline\n",
    "baseline = 1- y.mean()\n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27665, 180) (13627, 180) (27665,) (13627,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "X_train_s = ss.transform(X_train)\n",
    "X_test_s = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/freedom/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:718: UserWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"lbfgs failed to converge. Increase the number \"\n",
      "/Users/freedom/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:718: UserWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"lbfgs failed to converge. Increase the number \"\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   32.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max auc_roc: 0.879956623579\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegressionCV(n_jobs=-1,verbose=2)\n",
    "logreg.fit(X_train_s, y_train)\n",
    "print ('Max auc_roc:', logreg.scores_[1].mean(axis=0).max())  # is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.score(X_test_s, y_test)\n",
    "y_preds = logreg.predict(X_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13627 13627\n"
     ]
    }
   ],
   "source": [
    "print(len(y_test), len(y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    13627.000000\n",
       "mean         0.115359\n",
       "std          0.319467\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.000000\n",
       "max          1.000000\n",
       "Name: injury, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Confusion Matrix Shows That I Misclassified 1572 of the Real Positives\n",
    "* True Positives were 0!\n",
    "* False Negatives were 1572"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12055,     0],\n",
       "       [ 1572,     0]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred=y_preds, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88464078667351587"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred=y_preds, y_true=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Neighbors Classifier: Better at Finding True Positives, with a few False Positives Thrown In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.87609971,  0.87096774,  0.87527513,  0.8760088 ,  0.86647102,\n",
       "        0.86857562,  0.87591777,  0.8773862 ,  0.87518355,  0.87812041])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train_s,y_train)\n",
    "cross_val_score(knn, X_test_s,y_test, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_preds_knn =knn.predict(X_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11905   150]\n",
      " [ 1544    28]]\n"
     ]
    }
   ],
   "source": [
    "conmat = confusion_matrix(y_pred=y_preds_knn, y_true=y_test)\n",
    "print(conmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87568797240772001"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred=y_preds_knn, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017811704834605598"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test,y_preds_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.99      0.93     12055\n",
      "          1       0.16      0.02      0.03      1572\n",
      "\n",
      "avg / total       0.80      0.88      0.83     13627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_preds_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the Threshhold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_no_DL</th>\n",
       "      <th>pred_a_DL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>had_no_DL_after</th>\n",
       "      <td>11905</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>had_a_DL_after</th>\n",
       "      <td>1544</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pred_no_DL  pred_a_DL\n",
       "had_no_DL_after       11905        150\n",
       "had_a_DL_after         1544         28"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pp = knn.predict_proba(X_test_s)\n",
    "confusion = pd.DataFrame(conmat, \n",
    "                         index=['had_no_DL_after','had_a_DL_after'],\n",
    "                        columns=['pred_no_DL','pred_a_DL'])\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_0_pp</th>\n",
       "      <th>class_1_pp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_0_pp  class_1_pp\n",
       "0         1.0         0.0\n",
       "1         1.0         0.0\n",
       "2         1.0         0.0\n",
       "3         0.8         0.2\n",
       "4         0.8         0.2"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pp = pd.DataFrame(y_pp,\n",
    "                    columns=['class_0_pp','class_1_pp'])\n",
    "y_pp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IF we want to change the threshhold from 50/50, to reduce num of false negs, we need to move threshhold to left, like 10%, Add a new column to dataframe we just created and call it predicted class threshhold 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_0_pp</th>\n",
       "      <th>class_1_pp</th>\n",
       "      <th>pred_class_thresh10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_0_pp  class_1_pp  pred_class_thresh10\n",
       "0         1.0         0.0                    0\n",
       "1         1.0         0.0                    0\n",
       "2         1.0         0.0                    0\n",
       "3         0.8         0.2                    1\n",
       "4         0.8         0.2                    1"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pp['pred_class_thresh10'] = [1 if x >= .1 else 0 for x in y_pp.class_1_pp.values]\n",
    "#Going down 1 class values, list of predicted probabiliteis, reduced it by\n",
    "  # returning a 1 if that pp value >= 0.1\n",
    "y_pp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_no_DL</th>\n",
       "      <th>pred_a_DL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>had_no_DL_after</th>\n",
       "      <td>6826</td>\n",
       "      <td>5229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>had_a_DL_after</th>\n",
       "      <td>816</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pred_no_DL  pred_a_DL\n",
       "had_no_DL_after        6826       5229\n",
       "had_a_DL_after          816        756"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conmat_update = metrics.confusion_matrix(y_test, y_pp.pred_class_thresh10)\n",
    "confusion = pd.DataFrame(conmat_update, \n",
    "                         index=['had_no_DL_after','had_a_DL_after'],\n",
    "                         columns=['pred_no_DL','pred_a_DL'])\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_0_pp</th>\n",
       "      <th>class_1_pp</th>\n",
       "      <th>pred_class_thresh10</th>\n",
       "      <th>pred_class_thresh30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_0_pp  class_1_pp  pred_class_thresh10  pred_class_thresh30\n",
       "0         1.0         0.0                    0                    0\n",
       "1         1.0         0.0                    0                    0\n",
       "2         1.0         0.0                    0                    0\n",
       "3         0.8         0.2                    1                    0\n",
       "4         0.8         0.2                    1                    0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pp['pred_class_thresh30'] = [1 if x >= .3 else 0 for x in y_pp.class_1_pp.values]\n",
    "#Going down 1 class values, list of predicted probabiliteis, reduced it by\n",
    "  # returning a 1 if that pp value >= 0.1\n",
    "y_pp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_no_DL</th>\n",
       "      <th>pred_a_DL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>had_no_DL_after</th>\n",
       "      <td>10867</td>\n",
       "      <td>1188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>had_a_DL_after</th>\n",
       "      <td>1381</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pred_no_DL  pred_a_DL\n",
       "had_no_DL_after       10867       1188\n",
       "had_a_DL_after         1381        191"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conmat_update = metrics.confusion_matrix(y_test, y_pp.pred_class_thresh30)\n",
    "confusion = pd.DataFrame(conmat_update, \n",
    "                         index=['had_no_DL_after','had_a_DL_after'],\n",
    "                         columns=['pred_no_DL','pred_a_DL'])\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_no_DL</th>\n",
       "      <th>pred_a_DL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>had_no_DL_after</th>\n",
       "      <td>6826</td>\n",
       "      <td>5229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>had_a_DL_after</th>\n",
       "      <td>816</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pred_no_DL  pred_a_DL\n",
       "had_no_DL_after        6826       5229\n",
       "had_a_DL_after          816        756"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pp['pred_class_thresh20'] = [1 if x >= .2 else 0 for x in y_pp.class_1_pp.values]\n",
    "#Going down 1 class values, list of predicted probabiliteis, reduced it by\n",
    "  # returning a 1 if that pp value >= 0.1\n",
    "conmat_update = metrics.confusion_matrix(y_test, y_pp.pred_class_thresh20)\n",
    "confusion = pd.DataFrame(conmat_update, \n",
    "                         index=['had_no_DL_after','had_a_DL_after'],\n",
    "                         columns=['pred_no_DL','pred_a_DL'])\n",
    "confusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
